<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>Deep learning(3)_调参总结 | JonOnEarth</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><meta name="generator" content="Hexo 4.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Deep learning(3)_调参总结</h1><a id="logo" href="/.">JonOnEarth</a><p class="description">加油中国</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/DailyNote/"><i class="fa fa-user"> DailyNote</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Deep learning(3)_调参总结</h1><div class="post-meta">Jun 15, 2018<span> | </span><span class="category"><a href="/categories/%E6%9C%BA%E6%A2%B0%E5%85%AC%E6%95%8C/">机械公敌</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a class="disqus-comment-count" data-disqus-identifier="2018/06/15/调参总结/" href="/2018/06/15/%E8%B0%83%E5%8F%82%E6%80%BB%E7%BB%93/#disqus_thread"></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#超参数主要包括："><span class="toc-number">1.</span> <span class="toc-text">超参数主要包括：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实践经验"><span class="toc-number">2.</span> <span class="toc-text">实践经验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自动调参"><span class="toc-number">3.</span> <span class="toc-text">自动调参</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Optimizer"><span class="toc-number">4.</span> <span class="toc-text">Optimizer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Adam"><span class="toc-number">4.1.</span> <span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SGD"><span class="toc-number">4.2.</span> <span class="toc-text">SGD</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Resources"><span class="toc-number">5.</span> <span class="toc-text">Resources:</span></a></li></ol></div></div><div class="post-content"><p>调参的一些blog</p>
<p>本文blog主要整理自：（主要用于自己学习，不用做其它）<br><a href="https://blog.csdn.net/dugudaibo/article/details/77366245" target="_blank" rel="noopener">https://blog.csdn.net/dugudaibo/article/details/77366245</a></p>
<p><a href="https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/7366925.html" target="_blank" rel="noopener">Deep learning网络调参技巧</a></p>
<p>首先，调参调的是超参数（hyperparameters）。超参数和参数的区别是什么呢？</p>
<p>参数：就是模型可以根据数据可以自动学习出的变量，应该就是参数。比如，深度学习的权重，偏差等</p>
<p>超参数：就是用来确定模型的一些参数，超参数不同，模型是不同的(这个模型不同的意思就是有微小的区别，比如假设都是CNN模型，如果层数不同，模型不一样，虽然都是CNN模型哈。)，超参数一般就是根据经验确定的变量。在深度学习中，超参数有：学习速率，迭代次数，层数，每层神经元的个数等等。   from:  <a href="https://blog.csdn.net/UESTC_C2_403/article/details/77428736" target="_blank" rel="noopener">link</a>  </p>
<h2 id="超参数主要包括："><a href="#超参数主要包括：" class="headerlink" title="超参数主要包括："></a>超参数主要包括：</h2><ol>
<li>学习率 $\eta$</li>
</ol>
<p>1 0.1 0.01 0.001, 一般从1开始尝试。很少见learning rate大于10的。学习率一般要随着训练进行衰减。衰减系数一般是0.5。 衰减时机，可以是验证集准确率不再上升时，或固定训练多少个周期以后。    </p>
<p>不过更建议使用自适应梯度的办法，例如adam,adadelta,rmsprop等，这些一般使用相关论文提供的默认值即可，可以避免再费劲调节学习率。对RNN来说，有个经验，如果RNN要处理的序列比较长，或者RNN层数比较多，那么learning rate一般小一些比较好，否则有可能出现结果不收敛，甚至Nan等问题。</p>
<ol start="2">
<li>正则化参数 $\lambda$</li>
</ol>
<p>开始从1.0尝试，超过10的很少见</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">regularzation_penalty &#x3D; 0.02</span><br><span class="line">model.add(Dense(256, activation&#x3D;&#39;relu&#39;, kernel_regularizer&#x3D;regularizers.l2(regularzation_penalty)))</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>神经网络的层数 $L$</li>
</ol>
<p>先从1层开始试</p>
<ol start="4">
<li>每一个隐层中神经元的个数 $j$</li>
</ol>
<p>16 32 128，超过1000的情况比较少见。超过1W的从来没有见过</p>
<ol start="5">
<li><p>学习的回合数Epoch</p>
</li>
<li><p>小批量数据 minibatch 的大小</p>
</li>
</ol>
<p>128上下开始。batch size值增加，的确能提高训练速度。但是有可能收敛结果变差。如果显存大小允许，可以考虑从一个比较大的值开始尝试。因为batch size太大，一般不会对结果有太大的影响，而batch size太小的话，结果有可能很差。</p>
<ol start="7">
<li><p>输出神经元的编码方式(?不太明白这里)</p>
</li>
<li><p>代价函数的选择<br>代价函数有很多，例如, <a href="https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications" target="_blank" rel="noopener">更多cost function</a></p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss &#x3D; &#39;categorical_crossentropy&#39; #cross-entropy,</span><br><span class="line">loss &#x3D; mean_squared_error</span><br><span class="line">loss&#x3D;&#39;binary_crossentropy&#39;</span><br></pre></td></tr></table></figure>

<ol start="9">
<li>权重初始化的方法</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">initilization_method &#x3D; &#39;he_normal&#39; #&#39;random_uniform&#39; ,&#39;random_normal&#39;,&#39;TruncatedNormal&#39; ,&#39;glorot_uniform&#39;, &#39;glorot_nomral&#39;, &#39;he_normal&#39;, &#39;he_uniform&#39;</span><br><span class="line"></span><br><span class="line">model.add(Dense(256, input_dim&#x3D;256, activation&#x3D;&#39;relu&#39;, kernel_initializer&#x3D;initilization_method)</span><br></pre></td></tr></table></figure>

<ol start="10">
<li><p>神经元激活函数的种类<br>指的activation function，具体可以参考<a href="https://jononearth.com/%E6%9C%BA%E6%A2%B0%E5%85%AC%E6%95%8C/Deep-Learning-1/#Train-Optimization">deep learning(1)</a></p>
</li>
<li><p>参加训练模型数据的规模</p>
</li>
</ol>
<h2 id="实践经验"><a href="#实践经验" class="headerlink" title="实践经验"></a>实践经验</h2><p>实践中，一般先进行初步范围搜索，然后根据好结果出现的地方，再缩小范围进行更精细的搜索。</p>
<ol>
<li>建议先参考相关论文，以论文中给出的参数作为初始参数。至少论文中的参数，是个不差的结果。</li>
<li>如果找不到参考，那么只能自己尝试了。可以先从比较重要，对实验结果影响比较大的参数开始，同时固定其他参数，得到一个差不多的结果以后，在这个结果的基础上，再调其他参数。例如学习率一般就比正则值，dropout值重要的话，学习率设置的不合适，不仅结果可能变差，模型甚至会无法收敛。</li>
<li>如果实在找不到一组参数，可以让模型收敛。那么就需要检查，是不是其他地方出了问题，例如模型实现，数据等等。</li>
</ol>
<h2 id="自动调参"><a href="#自动调参" class="headerlink" title="自动调参"></a>自动调参</h2><ol>
<li>Grid Search</li>
<li>Random Search</li>
<li>Bayesian Optimization</li>
</ol>
<h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><p>按吴恩达老师所说的，梯度下降（Gradient Descent）就好比一个人想从高山上奔跑到山谷最低点，用最快的方式（steepest）奔向最低的位置（minimum）</p>
<p>这部分数学部分不做陈述，主要是代码应用。<br><a href="https://keras.io/optimizers/#adam" target="_blank" rel="noopener">keras optimizers</a></p>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p><a href="https://www.jianshu.com/p/aebcaf8af76e" target="_blank" rel="noopener">简单认识Adam优化器</a></p>
<p>随机梯度涉及到这几个参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.Adam(lr&#x3D;0.001, beta_1&#x3D;0.9, beta_2&#x3D;0.999, epsilon&#x3D;1e-08,</span><br><span class="line">decay&#x3D;0.0,amsgrad&#x3D;False)</span><br></pre></td></tr></table></figure>
<h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources:"></a>Resources:</h2><p><a href="https://blog.csdn.net/roslei/article/details/61916038" target="_blank" rel="noopener">18个技巧实战深度学习，资深研究员的血泪教训</a></p>
<p><a href="http://ruder.io/optimizing-gradient-descent/index.html" target="_blank" rel="noopener">optimizer总结</a><br><a href="http://ruder.io/deep-learning-optimization-2017/" target="_blank" rel="noopener">optimization for deep learning highlights in 2017</a></p>
<p><a href="https://blog.csdn.net/qq_20259459/article/details/70316511" target="_blank" rel="noopener">深度学习 14. 深度学习调参，CNN参数调参，各个参数理解和说明以及调整的要领。underfitting和overfitting的理解，过拟合的解释</a></p>
<p><a href="https://blog.csdn.net/xiaocong1990/article/details/72585696" target="_blank" rel="noopener">深度学习调参策略1</a><br><a href="https://blog.csdn.net/xiaocong1990/article/details/72585735" target="_blank" rel="noopener">深度学习调参策略2</a><br><a href="https://blog.csdn.net/chenzhi1992/article/details/52905569" target="_blank" rel="noopener">深度学习训练的小技巧，调参经验。总结与记录</a></p>
<p><a href="https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/7366925.html" target="_blank" rel="noopener">Deep learning网络调参技巧</a></p>
<p><a href="https://zhuanlan.zhihu.com/easyml" target="_blank" rel="noopener">知乎专栏：炼丹心得</a></p>
</div><div class="tags"><a href="/tags/deep-learning/">deep learning</a><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a href="/tags/%E8%B0%83%E5%8F%82/">调参</a></div><div class="post-nav"><a class="pre" href="/2018/06/21/Machine-learning-with-python-4-classical-algorithm/">Machine learning with python(4)_classical algorithm(持续跟新)</a><a class="next" href="/2018/06/04/machine-learning-with-python-3/">machine learning with python(3)</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://jononearth.com/2018/06/15/调参总结/';
    this.page.identifier = '2018/06/15/调参总结/';
    this.page.title = 'Deep learning(3)_调参总结';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//jononearth.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//jononearth.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://jononearth.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/code/" style="font-size: 15px;">code</a> <a href="/tags/Data-structure/" style="font-size: 15px;">Data structure</a> <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/ensmeble/" style="font-size: 15px;">ensmeble</a> <a href="/tags/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/" style="font-size: 15px;">经典算法</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/pandas/" style="font-size: 15px;">pandas</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/" style="font-size: 15px;">数据科学</a> <a href="/tags/numpy/" style="font-size: 15px;">numpy</a> <a href="/tags/%E5%BB%BA%E7%AB%99/" style="font-size: 15px;">建站</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/" style="font-size: 15px;">面试题</a> <a href="/tags/%E8%B0%83%E5%8F%82/" style="font-size: 15px;">调参</a> <a href="/tags/%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D/" style="font-size: 15px;">室内定位</a> <a href="/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E5%90%90/" style="font-size: 15px;">每日一吐</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E8%AF%9D%E4%B8%9C%E6%B8%B8/">大话东游</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AF%86%E5%AE%A4%E9%80%83%E8%84%B1/">密室逃脱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E6%A2%B0%E5%85%AC%E6%95%8C/">机械公敌</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">极客时间</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%BB%91%E5%AE%A2%E5%B8%9D%E5%9B%BD/">黑客帝国</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/05/02/2-3%E6%9C%88%E6%AF%8F%E6%97%A5%E4%B8%80%E5%90%90/">2-3月每日一吐</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/hello-world/">Hello World</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/01/2019%E6%80%BB%E7%BB%93%E5%A4%A7%E4%BC%9A/">2019总结大会</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/30/%E5%BB%BA%E7%AB%99%E5%A4%87%E5%BF%98/">建站备忘</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/29/2018-05-07-machine-leaning-index/">Machine Learning 资源汇总</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E4%B9%8B%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E6%95%B4%E7%90%86/">Indoor Positioning Resources Document</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/01/%E6%AF%8F%E6%97%A5%E4%B8%80%E5%90%90201812/">每日一吐201812</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/01/2019%E6%96%B0%E5%B9%B4flag/">2019新年flag</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9/">机器学习知识点</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Algorithm-1/">Data structure and algorithm(1)</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//jononearth.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">JonOnEarth.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>